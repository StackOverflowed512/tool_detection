import cv2
import numpy as np
import os
import math
from sklearn.ensemble import RandomForestClassifier
import joblib
import json
from typing import List, Dict, Tuple, Optional

class OrthopedicToolDetector:
    def __init__(self, model_path: str = None, pixel_to_mm: float = 0.1):
        """
        Initialize the detector for ACL/PCL jig set tools.
        
        Args:
            model_path: Path to trained ML model (optional)
            pixel_to_mm: Conversion factor from pixels to millimeters
        """
        # Tool-specific colors for visualization
        self.colors = {
            'drill_guide': (0, 255, 0),      # Green
            'depth_gauge': (0, 165, 255),    # Orange
            'sizing_block': (255, 0, 0),    # Blue
            'alignment_rod': (0, 0, 255),    # Red
            'tunnel_dilator': (255, 0, 255), # Purple
            'unknown': (128, 128, 128)       # Gray
        }
        
        # Detection thresholds and parameters
        self.thresholds = {
            'min_area': 500,                  # Minimum contour area to consider
            'circularity': 0.7,               # For circular tools
            'aspect_ratio': {                 # For rectangular tools
                'drill_guide': (1.5, 4.0),
                'depth_gauge': (3.0, 8.0),
                'sizing_block': (1.0, 1.5)
            },
            'solidity': 0.85,                 # For solid objects
            'hole_ratio': 0.2                 # For tools with holes
        }
        
        # Visualization settings
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.font_scale = 0.6
        self.font_thickness = 2
        self.text_color = (255, 255, 255)
        self.line_thickness = 2
        
        # Measurement conversion
        self.pixel_to_mm = pixel_to_mm
        
        # Classification model
        self.model = None
        self.classes = ['drill_guide', 'depth_gauge', 'sizing_block', 
                       'alignment_rod', 'tunnel_dilator', 'unknown']
        
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)

    def load_model(self, model_path: str):
        """Load a trained classification model"""
        try:
            self.model = joblib.load(model_path)
            print(f"Model loaded from {model_path}")
        except Exception as e:
            print(f"Error loading model: {e}")
            self.model = None

    def preprocess_image(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Preprocess the image for tool detection.
        
        Args:
            image: Input BGR image
            
        Returns:
            tuple: (binary_mask, grayscale_image)
        """
        if image is None or image.size == 0:
            return None, None
            
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Enhance contrast using CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        
        # Remove noise while preserving edges
        blurred = cv2.bilateralFilter(enhanced, 9, 75, 75)
        
        # Adaptive thresholding
        thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # Morphological operations to clean up
        kernel = np.ones((3, 3), np.uint8)
        cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel, iterations=1)
        
        return cleaned, gray

    def detect_tools(self, image: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        Detect and measure tools in the ACL/PCL jig set.
        
        Args:
            image: Input BGR image
            
        Returns:
            tuple: (annotated_image, detected_tools)
        """
        if image is None:
            return None, []
        
        # Preprocess the image
        mask, gray = self.preprocess_image(image)
        if mask is None:
            return image, []
        
        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Sort contours by area (largest first)
        contours = sorted(contours, key=cv2.contourArea, reverse=True)
        
        # Process each tool
        results = []
        result_image = image.copy()
        
        for i, contour in enumerate(contours):
            # Skip small contours
            if cv2.contourArea(contour) < self.thresholds['min_area']:
                continue
            
            # Extract features and classify
            features = self.extract_features(contour, gray)
            tool_type = self.classify_tool(features, contour)
            
            # Measure dimensions
            dimensions = self.measure_tool(contour, tool_type)
            
            if dimensions:
                results.append({
                    'id': i+1,
                    'type': tool_type,
                    'dimensions': dimensions,
                    'contour': contour.tolist()  # Convert for JSON serialization
                })
                
                # Draw results on image
                self.draw_detection(result_image, contour, tool_type, dimensions, i+1)
        
        return result_image, results

    def extract_features(self, contour: np.ndarray, gray_image: np.ndarray) -> List[float]:
        """Extract features from a contour for classification"""
        if contour is None or len(contour) < 5:
            return [0] * 8
            
        # Basic shape features
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        circularity = 4 * np.pi * area / (perimeter**2 + 1e-5)
        
        # Bounding rectangle features
        rect = cv2.minAreaRect(contour)
        _, (width, height), _ = rect
        aspect_ratio = max(width, height) / (min(width, height) + 1e-5)
        
        # Convexity features
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / (hull_area + 1e-5)
        
        # Hole detection
        has_hole, hole_ratio = self.detect_holes(contour, gray_image)
        
        return [
            area, perimeter, circularity, aspect_ratio, 
            solidity, has_hole, hole_ratio, len(contour)
        ]

    def detect_holes(self, contour: np.ndarray, gray_image: np.ndarray) -> Tuple[bool, float]:
        """Detect if the tool has holes and calculate hole ratio"""
        # Create mask for the tool
        mask = np.zeros(gray_image.shape, dtype=np.uint8)
        cv2.drawContours(mask, [contour], 0, 255, -1)
        
        # Find holes using contour hierarchy
        contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        
        has_hole = False
        hole_ratio = 0.0
        area = cv2.contourArea(contour)
        
        if hierarchy is not None:
            for i, (_, _, _, parent) in enumerate(hierarchy[0]):
                if parent >= 0:  # This is a hole (child contour)
                    hole_area = cv2.contourArea(contours[i])
                    if hole_area > area * 0.05:  # Minimum hole size threshold
                        has_hole = True
                        hole_ratio += hole_area / area
        
        return has_hole, hole_ratio

    def classify_tool(self, features: List[float], contour: np.ndarray) -> str:
        """Classify the tool using features or ML model"""
        if self.model is not None:
            try:
                features_array = np.array(features).reshape(1, -1)
                return self.model.predict(features_array)[0]
            except Exception as e:
                print(f"ML classification failed: {e}. Using rule-based.")
        
        # Rule-based classification
        area, _, circularity, aspect_ratio, solidity, has_hole, hole_ratio, _ = features
        
        # Drill guide - typically rectangular with holes
        if (self.thresholds['aspect_ratio']['drill_guide'][0] <= aspect_ratio <= 
            self.thresholds['aspect_ratio']['drill_guide'][1] and has_hole):
            return 'drill_guide'
            
        # Depth gauge - long and narrow
        if aspect_ratio >= self.thresholds['aspect_ratio']['depth_gauge'][0]:
            return 'depth_gauge'
            
        # Sizing block - more square with measurement markings
        if (self.thresholds['aspect_ratio']['sizing_block'][0] <= aspect_ratio <= 
            self.thresholds['aspect_ratio']['sizing_block'][1] and solidity > 0.9):
            return 'sizing_block'
            
        # Alignment rod - circular or cylindrical
        if circularity > self.thresholds['circularity']:
            return 'alignment_rod'
            
        # Tunnel dilator - has distinctive shape with holes
        if has_hole and hole_ratio > 0.15:
            return 'tunnel_dilator'
            
        return 'unknown'

    def measure_tool(self, contour: np.ndarray, tool_type: str) -> Dict[str, float]:
        """Measure dimensions of the tool in millimeters"""
        if contour is None or len(contour) < 5:
            return None
            
        # Get minimum area rectangle
        rect = cv2.minAreaRect(contour)
        center, (width, height), angle = rect
        
        # Convert to mm
        width_mm = width * self.pixel_to_mm
        height_mm = height * self.pixel_to_mm
        
        # Tool-specific measurements
        if tool_type == 'drill_guide':
            # Measure hole diameters and spacing
            return {
                'length': round(max(width_mm, height_mm), 1),
                'width': round(min(width_mm, height_mm), 1),
                'hole_diameter': self.measure_hole_diameter(contour),
                'hole_spacing': self.measure_hole_spacing(contour)
            }
        elif tool_type == 'depth_gauge':
            # Measure length and markings
            return {
                'length': round(max(width_mm, height_mm), 1),
                'diameter': round(min(width_mm, height_mm), 1),
                'markings': self.count_markings(contour)
            }
        elif tool_type == 'sizing_block':
            # Measure block dimensions and holes
            return {
                'width': round(width_mm, 1),
                'height': round(height_mm, 1),
                'thickness': self.estimate_thickness(contour)
            }
        elif tool_type == 'alignment_rod':
            # Measure diameter
            (x, y), radius = cv2.minEnclosingCircle(contour)
            return {
                'diameter': round(2 * radius * self.pixel_to_mm, 1),
                'length': self.estimate_length(contour)
            }
        elif tool_type == 'tunnel_dilator':
            # Measure outer and inner diameters
            return {
                'outer_diameter': round(max(width_mm, height_mm), 1),
                'inner_diameter': round(min(width_mm, height_mm), 1),
                'taper_angle': self.calculate_taper(contour)
            }
        else:
            # Generic measurements
            return {
                'width': round(width_mm, 1),
                'height': round(height_mm, 1)
            }

    def measure_hole_diameter(self, contour: np.ndarray) -> float:
        """Measure hole diameter for drill guides"""
        # This is a simplified version - would need actual hole detection
        # For actual implementation, would detect holes and measure their diameters
        return round(5.0 * self.pixel_to_mm, 1)  # Placeholder

    def measure_hole_spacing(self, contour: np.ndarray) -> float:
        """Measure distance between holes in drill guides"""
        # Placeholder - would need actual hole detection and measurement
        return round(10.0 * self.pixel_to_mm, 1)

    def count_markings(self, contour: np.ndarray) -> int:
        """Count measurement markings on depth gauges"""
        # Placeholder - would need advanced image processing
        return 10

    def estimate_thickness(self, contour: np.ndarray) -> float:
        """Estimate thickness of sizing blocks"""
        # Placeholder - would need 3D information or multiple views
        return round(5.0 * self.pixel_to_mm, 1)

    def estimate_length(self, contour: np.ndarray) -> float:
        """Estimate length of alignment rods"""
        # For cylindrical objects, length may not be visible in 2D
        return round(100.0 * self.pixel_to_mm, 1)  # Placeholder

    def calculate_taper(self, contour: np.ndarray) -> float:
        """Calculate taper angle for tunnel dilators"""
        # Would need to detect edges and calculate angle
        return 5.0  # degrees placeholder

    def draw_detection(self, image: np.ndarray, contour: np.ndarray, 
                      tool_type: str, dimensions: Dict[str, float], item_id: int):
        """Draw detection results on the image"""
        color = self.colors.get(tool_type, self.colors['unknown'])
        
        # Draw contour
        cv2.drawContours(image, [contour], 0, color, self.line_thickness)
        
        # Get bounding rectangle for text placement
        x, y, w, h = cv2.boundingRect(contour)
        
        # Format dimensions string based on tool type
        dim_str = self.format_dimensions(tool_type, dimensions)
        
        # Draw tool type and ID
        cv2.putText(
            image, f"#{item_id}: {tool_type.replace('_', ' ').title()}", 
            (x, y-10), self.font, self.font_scale, self.text_color, self.font_thickness
        )
        
        # Draw dimensions
        cv2.putText(
            image, dim_str, 
            (x, y+h+20), self.font, self.font_scale*0.8, self.text_color, self.font_thickness
        )

    def format_dimensions(self, tool_type: str, dimensions: Dict[str, float]) -> str:
        """Format dimensions string based on tool type"""
        if tool_type == 'drill_guide':
            return f"L: {dimensions['length']}mm W: {dimensions['width']}mm | Hole Ø: {dimensions['hole_diameter']}mm"
        elif tool_type == 'depth_gauge':
            return f"L: {dimensions['length']}mm | Ø: {dimensions['diameter']}mm | Markings: {dimensions['markings']}"
        elif tool_type == 'sizing_block':
            return f"W: {dimensions['width']}mm H: {dimensions['height']}mm T: {dimensions['thickness']}mm"
        elif tool_type == 'alignment_rod':
            return f"Ø: {dimensions['diameter']}mm | L: {dimensions['length']}mm"
        elif tool_type == 'tunnel_dilator':
            return f"Outer Ø: {dimensions['outer_diameter']}mm | Inner Ø: {dimensions['inner_diameter']}mm"
        else:
            return f"W: {dimensions['width']}mm H: {dimensions['height']}mm"

    def calibrate_scale(self, image: np.ndarray, reference_length_mm: float) -> bool:
        """
        Calibrate the pixel-to-mm conversion using a known reference length.
        
        Args:
            image: Input image containing a reference object
            reference_length_mm: Known length of the reference object in mm
            
        Returns:
            bool: True if calibration succeeded
        """
        print("Please select the reference object by drawing a line along its known dimension.")
        print("Press 'c' to confirm the selection or 'q' to cancel.")
        
        # In a real implementation, this would use cv2.setMouseCallback()
        # to let the user draw a line on the reference object
        
        # For demonstration, we'll use a placeholder value
        measured_pixels = 100  # This would come from user input
        if measured_pixels > 0:
            self.pixel_to_mm = reference_length_mm / measured_pixels
            print(f"Calibration complete: 1 pixel = {self.pixel_to_mm:.4f} mm")
            return True
        return False

    def save_results(self, results: List[Dict], output_path: str):
        """Save detection results to a JSON file"""
        try:
            with open(output_path, 'w') as f:
                json.dump(results, f, indent=2)
            print(f"Results saved to {output_path}")
        except Exception as e:
            print(f"Error saving results: {e}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ACL/PCL Jig Set Tool Detector')
    parser.add_argument('image_path', help='Path to the input image')
    parser.add_argument('--model', help='Path to trained model (optional)')
    parser.add_argument('--output', default='result.jpg', help='Output image path')
    parser.add_argument('--json', help='Path to save JSON results')
    parser.add_argument('--calibrate', type=float, help='Reference length in mm for calibration')
    args = parser.parse_args()
    
    # Load image
    image = cv2.imread(args.image_path)
    if image is None:
        print(f"Error: Could not load image from {args.image_path}")
        return
    
    # Initialize detector
    detector = OrthopedicToolDetector(model_path=args.model)
    
    # Calibrate if requested
    if args.calibrate:
        if not detector.calibrate_scale(image, args.calibrate):
            print("Calibration failed")
            return
    
    # Detect tools
    result_image, tools = detector.detect_tools(image)
    
    # Display and save results
    cv2.imshow("Tool Detection", result_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    cv2.imwrite(args.output, result_image)
    print(f"Result image saved to {args.output}")
    
    if args.json:
        detector.save_results(tools, args.json)
    
    # Print summary
    print(f"\nDetected {len(tools)} tools:")
    for tool in tools:
        print(f"Tool #{tool['id']}: {tool['type'].replace('_', ' ').title()}")
        for dim, value in tool['dimensions'].items():
            print(f"  {dim}: {value}")
        print()

if __name__ == "__main__":
    main()